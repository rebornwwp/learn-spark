{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .master('local') \\\n",
    "        .appName('test') \\\n",
    "        .config('spark.executor.memory', '1gb') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "        (1, 144.5, 5.9, 33, 'M'),\n",
    "        (2, 167.2, 5.4, 45, 'M'),\n",
    "        (3, 124.1, 5.2, 23, 'F'),\n",
    "        (4, 144.5, 5.9, 33, 'M'),\n",
    "        (5, 133.2, 5.7, 54, 'F'),\n",
    "        (3, 124.1, 5.2, 23, 'F'),\n",
    "        (5, 129.2, 5.3, 42, 'M'),\n",
    "    ], ['id', 'weight', 'height', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of rows: 7\n",
      "count of distinct rows: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"count of rows: {0}\".format(df.count()))\n",
    "print(\"count of distinct rows: {0}\".format(df.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropDuplicates()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ids: 6\n",
      "Count of distinct ids: 5\n"
     ]
    }
   ],
   "source": [
    "print('Count of ids: {0}'.format(df.count()))\n",
    "print('Count of distinct ids: {0}'.format(df.select([c for c in df.columns if c != 'id']).distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropDuplicates(subset=[c for c in df.columns if c != 'id'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|count|distinct|\n",
      "+-----+--------+\n",
      "|    5|       4|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as fn\n",
    "\n",
    "df.agg(\n",
    "    fn.count('id').alias('count'),\n",
    "    fn.countDistinct('id').alias('distinct')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+-------------+\n",
      "| id|weight|height|age|gender|       new_id|\n",
      "+---+------+------+---+------+-------------+\n",
      "|  5| 133.2|   5.7| 54|     F|  25769803776|\n",
      "|  1| 144.5|   5.9| 33|     M| 171798691840|\n",
      "|  2| 167.2|   5.4| 45|     M| 592705486848|\n",
      "|  3| 124.1|   5.2| 23|     F|1236950581248|\n",
      "|  5| 129.2|   5.3| 42|     M|1365799600128|\n",
      "+---+------+------+---+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# give each row a unique ID\n",
    "df.withColumn('new_id', fn.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing obervations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = spark.createDataFrame([\n",
    "        (1, 143.5, 5.6, 28,   'M',  100000),\n",
    "        (2, 167.2, 5.4, 45,   'M',  None),\n",
    "        (3, None , 5.2, None, None, None),\n",
    "        (4, 144.5, 5.9, 33,   'M',  None),\n",
    "        (5, 133.2, 5.7, 54,   'F',  None),\n",
    "        (6, 124.1, 5.2, None, 'F',  None),\n",
    "        (7, 129.2, 5.3, 42,   'M',  76000),\n",
    "    ], ['id', 'weight', 'height', 'age', 'gender', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 4), (4, 1), (5, 1), (6, 2), (7, 0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss.rdd.map(\n",
    "    lambda row: (row['id'], sum([c == None for c in row]))\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.where('id == 3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|id_missing|    weight_missing|height_missing|       age_missing|    gender_missing|    income_missing|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|       0.0|0.1428571428571429|           0.0|0.2857142857142857|0.1428571428571429|0.7142857142857143|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.agg(*[\n",
    "    (1-(fn.count(c) / fn.count('*'))).alias(c+'_missing')\n",
    "    for c in df_miss.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  3|  null|   5.2|null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop columns\n",
    "df_miss_no_income = df_miss.select([c for c in df_miss.columns if c != 'income'])\n",
    "df_miss_no_income.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss_no_income.dropna(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+-------+\n",
      "| id|            weight|height|age| gender|\n",
      "+---+------------------+------+---+-------+\n",
      "|  1|             143.5|   5.6| 28|      M|\n",
      "|  2|             167.2|   5.4| 45|      M|\n",
      "|  3|140.28333333333333|   5.2| 40|missing|\n",
      "|  4|             144.5|   5.9| 33|      M|\n",
      "|  5|             133.2|   5.7| 54|      F|\n",
      "|  6|             124.1|   5.2| 40|      F|\n",
      "|  7|             129.2|   5.3| 42|      M|\n",
      "+---+------------------+------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill the na value\n",
    "means = df_miss_no_income.agg(\n",
    "    *[fn.mean(c).alias(c) for c in df_miss_no_income.columns if c != 'gender']\n",
    ").toPandas().to_dict('records')[0]\n",
    "means['gender'] = 'missing'\n",
    "df_miss_no_income.fillna(means).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 40.4,\n",
       " 'gender': 'missing',\n",
       " 'height': 5.471428571428571,\n",
       " 'id': 4.0,\n",
       " 'weight': 140.28333333333333}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = spark.createDataFrame([\n",
    "        (1, 143.5, 5.3, 28),\n",
    "        (2, 154.2, 5.5, 45),\n",
    "        (3, 342.3, 5.1, 99),\n",
    "        (4, 144.5, 5.5, 33),\n",
    "        (5, 133.2, 5.4, 54),\n",
    "        (6, 124.1, 5.1, 21),\n",
    "        (7, 129.2, 5.3, 42),\n",
    "    ], ['id', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['weight', 'height', 'age']\n",
    "bounds = {}\n",
    "for col in cols:\n",
    "    quantiles = df_outliers.approxQuantile(col, [0.25, 0.75], 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    bounds[col] = [quantiles[0] - 1.5 * IQR, quantiles[1] + 1.5 * IQR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [-11.0, 93.0],\n",
       " 'height': [4.499999999999999, 6.1000000000000005],\n",
       " 'weight': [91.69999999999999, 191.7]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+\n",
      "| id|weight_o|height_o|age_o|\n",
      "+---+--------+--------+-----+\n",
      "|  1|   false|   false|false|\n",
      "|  2|   false|   false|false|\n",
      "|  3|    true|   false| true|\n",
      "|  4|   false|   false|false|\n",
      "|  5|   false|   false|false|\n",
      "|  6|   false|   false|false|\n",
      "|  7|   false|   false|false|\n",
      "+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df_outliers.select(*['id'] + [\n",
    "    (\n",
    "        (df_outliers[c] < bounds[c][0]) |\n",
    "        (df_outliers[c] > bounds[c][1])\n",
    "    ).alias(c + '_o') for c in cols\n",
    "])\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  3| 342.3|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers = df_outliers.join(outliers, on='id')\n",
    "df_outliers.filter('weight_o').select('id', 'weight').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|  3| 99|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(\"age_o\").select('id', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------+--------+-----+\n",
      "| id|weight|height|age|weight_o|height_o|age_o|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "|  7| 129.2|   5.3| 42|   false|   false|false|\n",
      "|  6| 124.1|   5.1| 21|   false|   false|false|\n",
      "|  5| 133.2|   5.4| 54|   false|   false|false|\n",
      "|  1| 143.5|   5.3| 28|   false|   false|false|\n",
      "|  3| 342.3|   5.1| 99|    true|   false| true|\n",
      "|  2| 154.2|   5.5| 45|   false|   false|false|\n",
      "|  4| 144.5|   5.5| 33|   false|   false|false|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datafram with csv file\n",
    "fraud = sc.textFile('ccFraud.csv.gz')\n",
    "header = fraud.first()\n",
    "\n",
    "fraud = fraud \\\n",
    "    .filter(lambda row: row != header) \\\n",
    "    .map(lambda row: [int(elem) for elem in row.split(',')])\n",
    "\n",
    "# support in python3\n",
    "a = [1,2,3,4]\n",
    "a = [*a]\n",
    "\n",
    "fields = [\n",
    "    *[\n",
    "        typ.StructField(h[1:-1], typ.IntegerType(), True)\n",
    "        for h in header.split(',')\n",
    "    ]\n",
    "]\n",
    "\n",
    "schema = typ.StructType(fields)\n",
    "fraud_df = spark.createDataFrame(fraud, schema)\n",
    "\n",
    "fraud_df.groupby('gender').count().show()\n",
    "\n",
    "numerical = ['balance', 'numTrans', 'numIntlTrans']\n",
    "desc = fraud_df.describe(numerical)\n",
    "desc.show()\n",
    "\n",
    "fraud_df.agg({'balance': 'skewness'}).show()\n",
    "\n",
    "\n",
    "fraud_df.corr('balance', 'numTrans')\n",
    "\n",
    "# histograms\n",
    "hists = fraud_df.select('balance').rdd.flatMap(lambda row: row).histogram(20)\n",
    "data_sample = fraud_df.sampleBy('gender', {1: 0.0002, 2: 0.0002}).select(numerical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
