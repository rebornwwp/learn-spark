{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classication and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PythonPi\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.353983524188197e-05,-9.102738505589466e-05,-0.00019467430546904298,-0.00020300642473486668,-3.1476183314863995e-05,-6.842977602660743e-05,1.5883626898239883e-05,1.4023497091372047e-05,0.00035432047524968605,0.00011443272898171087,0.00010016712383666666,0.0006014109303795481,0.0002840248179122762,-0.00011541084736508837,0.000385996886312906,0.000635019557424107,-0.00011506412384575676,-0.00015271865864986808,0.0002804933808994214,0.0006070117471191634,-0.0002008459663247437,-0.0001421075579290126,0.0002739010341160883,0.00027730456244968115,-9.838027027269332e-05,-0.0003808522443517704,-0.00025315198008555033,0.00027747714770754307,-0.0002443619763919199,-0.0015394744687597765,-0.00023073328411331293])\n",
      "Intercept: 0.22456315961250325\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# load data\n",
    "training = spark.read.format(\"libsvm\").load(\"/Users/reborn/spark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: 2 X 692 CSRMatrix\n",
      "(0,244) 0.0\n",
      "(0,263) 0.0001\n",
      "(0,272) 0.0001\n",
      "(0,300) 0.0001\n",
      "(0,350) -0.0\n",
      "(0,351) -0.0\n",
      "(0,378) -0.0\n",
      "(0,379) -0.0\n",
      "(0,405) -0.0\n",
      "(0,406) -0.0006\n",
      "(0,407) -0.0001\n",
      "(0,428) 0.0001\n",
      "(0,433) -0.0\n",
      "(0,434) -0.0007\n",
      "(0,455) 0.0001\n",
      "(0,456) 0.0001\n",
      "..\n",
      "..\n",
      "Intercept: [-0.12065879445860686,0.12065879445860686]\n"
     ]
    }
   ],
   "source": [
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "print(\"Coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6833149135741672\n",
      "0.6662875751473734\n",
      "0.6217068546034618\n",
      "0.6127265245887887\n",
      "0.6060347986802873\n",
      "0.6031750687571562\n",
      "0.5969621534836274\n",
      "0.5940743031983118\n",
      "0.5906089243339022\n",
      "0.5894724576491042\n",
      "0.5882187775729587\n",
      "+---+--------------------+\n",
      "|FPR|                 TPR|\n",
      "+---+--------------------+\n",
      "|0.0|                 0.0|\n",
      "|0.0|0.017543859649122806|\n",
      "|0.0| 0.03508771929824561|\n",
      "|0.0| 0.05263157894736842|\n",
      "|0.0| 0.07017543859649122|\n",
      "|0.0| 0.08771929824561403|\n",
      "|0.0| 0.10526315789473684|\n",
      "|0.0| 0.12280701754385964|\n",
      "|0.0| 0.14035087719298245|\n",
      "|0.0| 0.15789473684210525|\n",
      "|0.0| 0.17543859649122806|\n",
      "|0.0| 0.19298245614035087|\n",
      "|0.0| 0.21052631578947367|\n",
      "|0.0| 0.22807017543859648|\n",
      "|0.0| 0.24561403508771928|\n",
      "|0.0|  0.2631578947368421|\n",
      "|0.0|  0.2807017543859649|\n",
      "|0.0|  0.2982456140350877|\n",
      "|0.0|  0.3157894736842105|\n",
      "|0.0|  0.3333333333333333|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_4462af9d3369ccb4eb2e"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "3 X 4 CSRMatrix\n",
      "(0,3) 0.3176\n",
      "(1,2) -0.7804\n",
      "(1,3) -0.377\n",
      "Intercept: [0.05165231659832854,-0.12391224990853622,0.07225993331020768]\n",
      "objecticeHistory:\n",
      "1.098612288668108\n",
      "1.087602085441699\n",
      "1.0341156572156232\n",
      "1.0289859520256006\n",
      "1.0300389657358995\n",
      "1.0239965158223991\n",
      "1.0236097451839508\n",
      "1.0231082121970012\n",
      "1.023022220302788\n",
      "1.0230018151780262\n",
      "1.0229963739557606\n",
      "False positive rate by label:\n",
      "label 0:0.22\n",
      "label 1:0.05\n",
      "label 2:0.0\n",
      "False positive rate by label:\n",
      "label 0:1.0\n",
      "label 1:1.0\n",
      "label 2:0.46\n",
      "Precision by label:\n",
      "label 0: 0.6944444444444444\n",
      "label 1: 0.9090909090909091\n",
      "label 2: 1.0\n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "label 2: 0.46\n",
      "F-measure by label:\n",
      "label 0: 0.819672131147541\n",
      "label 1: 0.9523809523809523\n",
      "label 2: 0.6301369863013699\n",
      "Accuracy: 0.82\n",
      "FPR: 0.09\n",
      "TPR: 0.82\n",
      "F-measure: 0.8007300232766211\n",
      "Precision: 0.8678451178451179\n",
      "Recall: 0.82\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "training = spark \\\n",
    "            .read \\\n",
    "            .format(\"libsvm\") \\\n",
    "            .load(\"/Users/reborn/spark/data/mllib/sample_multiclass_classification_data.txt\")\n",
    "            \n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objecticeHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d:%s\" % (i, rate))\n",
    "\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d:%s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|(692,[95,96,97,12...|\n",
      "|       1.0|         1.0|(692,[122,123,148...|\n",
      "|       1.0|         1.0|(692,[123,124,125...|\n",
      "|       1.0|         1.0|(692,[124,125,126...|\n",
      "|       1.0|         1.0|(692,[125,126,127...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0 \n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4e5dbc3b444339ef69d9) of depth 2 with 5 nodes\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "data = spark.read.format(\"libsvm\").load(\"/Users/reborn/spark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorIndexer_438ba61194306b203c55"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(692,[95,96,97,12...|\n",
      "|           0.0|  0.0|(692,[98,99,100,1...|\n",
      "|           0.0|  0.0|(692,[122,123,124...|\n",
      "|           0.0|  0.0|(692,[122,123,148...|\n",
      "|           0.0|  0.0|(692,[123,124,125...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_44349e17e2875a359a10) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"/Users/reborn/spark/data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
